{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os, glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, SimpleRNN\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qlike(y_true, y_pred):\n",
    "    return K.mean((K.log(y_pred) + (y_true / y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename for Summary Table: Summary_DJIA30.csv\n"
     ]
    }
   ],
   "source": [
    "#Summary Table\n",
    "csv = (glob.glob('*.csv'))[0]\n",
    "print ('Filename for Summary Table: ' + csv)\n",
    "\n",
    "#Data Preparation from CSV  \n",
    "df_Summary = pd.read_csv(csv,index_col=0,engine = 'python')\n",
    "n_days = 252 #Number of days to use as dataset based on average trading days per year \n",
    "\n",
    "#Define empty array\n",
    "dataset = np.empty((n_days, 0)) # Preallocate the array\n",
    "\n",
    "#Create Dataset\n",
    "for i in range(0, len(df_Summary)):\n",
    "    try:\n",
    "        ticker = df_Summary['Ticker'][i]\n",
    "        df_ticker = pd.read_csv('Data//'+ ticker + '//' + ticker + '.csv',engine = 'python')\n",
    "\n",
    "        #Create new dataset array based on 'Return_log' and 'Realized_Volatility_20D'\n",
    "        asset=df_ticker[['Ret_Log','R_Vol_20D']].tail(n_days).values\n",
    "        dataset = np.append(dataset, asset, axis=1)\n",
    "    \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "factor = 2\n",
    "\n",
    "# Calculate second raw moment\n",
    "M2 = np.mean(dataset ** 2, axis=0) ** (1/2)\n",
    "\n",
    "# Apply scaling\n",
    "dataset_norm = (1/factor) * (dataset / M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    \"\"\"\n",
    "    Function to convert series from dataset to supervised learning\n",
    "    \"\"\"\n",
    "    data_x, data_y = [], []\n",
    "\n",
    "    for i in range(len(dataset) - look_back):\n",
    "\n",
    "        # Create sequence of length equal to look_back\n",
    "        x = dataset[i:(i + look_back), :]\n",
    "        data_x.append(x)\n",
    "\n",
    "        # Take just the volatility for the target\n",
    "        data_y.append(dataset[i + look_back, 1::2])\n",
    "\n",
    "    return np.array(data_x), np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series to supervised learning problem\n",
    "look_back = 20\n",
    "X, y = create_dataset(dataset_norm, look_back)\n",
    "\n",
    "# Declare variables\n",
    "n_features = dataset.shape[1]\n",
    "n_assets = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (20,0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3ef80a64ab31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Prepare the 3D input vector for the LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    290\u001b[0m            [5, 6]])\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (20,0)"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "training_days = 90\n",
    "X_train, X_test = X[:training_days], X[training_days:]\n",
    "y_train, y_test = y[:training_days], y[training_days:]\n",
    "\n",
    "# Prepare the 3D input vector for the LSTM\n",
    "X_train = np.reshape(X_train, (-1, look_back, n_features))\n",
    "X_test = np.reshape(X_test, (-1, look_back, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(len(dataset[0]),\n",
    "               input_shape=(look_back, n_features),\n",
    "               batch_size=batch_size,\n",
    "               return_sequences=True,\n",
    "               stateful=True,\n",
    "               activity_regularizer=regularizers.l1_l2(),\n",
    "               recurrent_regularizer=regularizers.l1_l2()))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(int(len(dataset[0])/2),\n",
    "               return_sequences=False,\n",
    "               stateful=True,\n",
    "               activity_regularizer=regularizers.l1_l2(),\n",
    "               recurrent_regularizer=regularizers.l1_l2()))\n",
    "model.add(Dense(n_assets, activation='softplus'))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the LSTM model\n",
    "model.compile(loss=qlike, optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and evaluating the model (On-line learning)\n",
    "\n",
    "# Create empty arrays\n",
    "y_pred = np.empty((0, n_assets))\n",
    "y_true = np.empty((0, n_assets))\n",
    "\n",
    "for j in range(training_days - look_back + 1, X.shape[0]):\n",
    "\n",
    "    if j == (training_days - look_back + 1):\n",
    "\n",
    "        # First training days for training\n",
    "        X_train = X[:j]\n",
    "        y_train = y[:j]\n",
    "\n",
    "        # Next day for forecasting\n",
    "        X_test = X[j].reshape(1, look_back, n_features)\n",
    "\n",
    "        # Ensure the correct shape for LSTM\n",
    "        X_test = np.tile(X_test, (batch_size, 1, 1))\n",
    "        y_test = np.tile(y[j], (batch_size, 1))\n",
    "\n",
    "        # Training epochs\n",
    "        epochs = 90\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # Available data to refine network state\n",
    "        X_train = X_test\n",
    "        y_train = y_test\n",
    "\n",
    "        # Ensure the correct shape for LSTM\n",
    "        X_test = X[j].reshape(1, look_back, n_features)\n",
    "        X_test = np.tile(X_test, (batch_size, 1, 1))\n",
    "        y_test = np.tile(y[j], (batch_size, 1))\n",
    "\n",
    "        # Epochs for updating\n",
    "        epochs = 20\n",
    "        \n",
    "    # Fit the model\n",
    "    for i in range(epochs):\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=1,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=0,\n",
    "                  shuffle=False)\n",
    "        model.reset_states()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    # Make predictions\n",
    "    predicted_output = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    predicted_output = predicted_output[0].reshape(1, n_assets)\n",
    "    true_output = y_test[0].reshape(1, n_assets)\n",
    "\n",
    "    # Save current prediction into an array\n",
    "    y_pred = np.append(y_pred, predicted_output, axis=0)\n",
    "    y_true = np.append(y_true, true_output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert scaling\n",
    "def invert_standardization(data, M2, factor):\n",
    "  \n",
    "    # Consider just volatility series\n",
    "    M2 = M2[1::2]\n",
    "\n",
    "    data = factor * data * M2\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply inversion\n",
    "y_pred = invert_standardization(y_pred, M2, factor)\n",
    "y_true = invert_standardization(y_true, M2, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate MSE and QLIKE\n",
    "    \"\"\"\n",
    "\n",
    "    mse = []\n",
    "    qlike = []\n",
    "\n",
    "    for i in range(0, int(len(dataset[0])/2)):\n",
    "        ticker = df_Summary['Ticker'][i]\n",
    "        mse_i = (y_true[:, i] - y_pred[:, i]) ** 2\n",
    "        qlike_i = np.log(y_pred[:, i]) + (y_true[:, i] /  y_pred[:, i])\n",
    "\n",
    "        # save results (point by point)\n",
    "        results = np.array([mse_i, qlike_i]).transpose()\n",
    "        np.savetxt('Data//' + ticker + '//' + ticker + '_RNN.csv', results, \n",
    "                   delimiter=',', header='MSE, Q-LIKE', fmt='%10.5f', comments='')\n",
    "        mse.append(np.mean(mse_i, axis=0))\n",
    "        qlike.append(np.mean(qlike_i, axis=0))\n",
    "\n",
    "    return mse, qlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply EVALUATE function to predictions\n",
    "mse, qlike = evaluate(y_true, y_pred)\n",
    "\n",
    "# save results\n",
    "results = np.array([mse, qlike]).transpose()\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'MSE_RNN': mse, 'QLIKE_RNN': qlike})\n",
    "print(df.describe())\n",
    "\n",
    "df_Summary['MSE_RNN'] = df['MSE_RNN'] \n",
    "df_Summary['QLIKE_RNN'] = df['QLIKE_RNN'] \n",
    "df_Summary.to_csv(csv,encoding='utf-8', index=True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
